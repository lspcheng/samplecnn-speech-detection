#!/usr/bin/env python3

import os
import tempfile
import ffmpeg
import argparse
import librosa
import torch
from samplecnn import SampleCNN

MICRO = "\U0001F3A4"
MUSIC = "\U0001F3B6"

SCRIPT_PATH = os.path.dirname(os.path.realpath(__file__))
MODEL_PATH = os.path.join(SCRIPT_PATH, "model-gztan-speech-music-20000.pth")

def strfdelta(t):
    d = {}
    d["h"], rem = divmod(t, 3600)
    d["m"], d["s"] = divmod(rem, 60)
    return d

parser = argparse.ArgumentParser(description="Speech/Music discriminator.")
parser.add_argument("-a", "--alpha", type=float, default=0.5, help="Cutoff point (0..1)")
parser.add_argument("audiofile", help="Audio file.")

args = parser.parse_args()

if not os.path.exists('output'):
    os.makedirs('output')

with tempfile.TemporaryDirectory(suffix="-discriminator") as tmpdir:
    # Get name of audiofile
    fn = os.path.splitext(args.audiofile)[0]
    av = str(args.alpha).replace(".", "")
    raw_out = os.path.join('output','{0}_{1}_raw_output.txt'.format(fn, av))
    text_out = os.path.join('output','{0}_{1}_text_output.txt'.format(fn, av))

    # Convert input to proper format (16 kHz, mono)
    output = os.path.join(tmpdir, "16khz.wav")
    (
        ffmpeg.input(args.audiofile)
              .output(output, format="wav", acodec="pcm_s16le", ac=1, ar="16k")
              .overwrite_output()
              .run()
    )
    # Instantiate CNN
    net = SampleCNN()
    net.load_state_dict(torch.load(MODEL_PATH))
    net.eval()

    count_list = []
    with open(raw_out, "w") as raw_file, open(text_out, "w") as text_file:
        with torch.no_grad():
            # Iterate through frames
            for i, frame in enumerate(map(torch.Tensor, librosa.core.stream(output, 1, 59049, 16000, fill_value=0))):
                y = net(frame.reshape(1, -1))
                y = y.item()

                # print(i)
                if i == 0:
                    if y > args.alpha:
                        y_status = current_status = 'speech'
                    else:
                        y_status = current_status = 'music'
                elif current_status == 'speech':
                    y_status = current_status
                    if y < args.alpha:
                        y_status = 'music'
                elif current_status == 'music':
                    y_status = current_status
                    if y > (1 - args.alpha):
                        y_status = 'speech'

                if not y_status == current_status:
                    count_list.append((i, y))
                else:
                    count_list = []
                # print(count_list)

                if len(count_list) == 4:
                    current_status = y_status
                    print('Insert boundary at time: {0}'.format(count_list[0][0]))
                #
                # print(current_status, y_status)
                # input()

                raw_line = "\t".join(["{h:02d}:{m:02d}:{s:02d}".format(**strfdelta(i)), "{} ({:.3f})".format(MICRO if y > args.alpha else MUSIC, y)])
                print(raw_line)

                text_line = "\t".join(["{h:02d}:{m:02d}:{s:02d}".format(**strfdelta(i)), "{} ({:.3f})".format('speech' if y > args.alpha else 'music', y)])
                # print(i)

                raw_file.write(raw_line+"\n")
                text_file.write(text_line+"\n")
